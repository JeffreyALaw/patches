diff --git a/gcc/ext-dce.cc b/gcc/ext-dce.cc
index 6d4b8858ec6..910705d0ab7 100644
--- a/gcc/ext-dce.cc
+++ b/gcc/ext-dce.cc
@@ -48,6 +48,32 @@ static bool modify;
    bit 16..31
    bit 32..BITS_PER_WORD-1  */
 
+static int
+group_limit (rtx reg)
+{
+  return exact_log2 (GET_MODE_SIZE (GET_MODE (reg)).to_constant ());
+}
+
+/* Given the bit tracking shown above, make all bit groups live
+   for REGNO in bitmap BMAP.  For hard regs, we assume all groups are
+   live.  For a pseudo we consider the size of the pseudo to avoid
+   creating unnecessarily live chunks of data.  */
+
+static void
+make_reg_live (bitmap bmap, int regno)
+{
+  int limit;
+  if (regno > FIRST_PSEUDO_REGISTER)
+    {
+      rtx reg = regno_reg_rtx[regno];
+      limit = group_limit (reg) + 1;
+    }
+  else
+    limit = 4;
+  for (int i = 0; i < limit; i++)
+    bitmap_set_bit (bmap, regno * 4 + limit);
+}
+
 /* Note this pass could be used to narrow memory loads too.  It's
    not clear if that's profitable or not in general.  */
 
@@ -129,9 +155,11 @@ safe_for_live_propagation (rtx_code code)
    within an object) are set by INSN, the more aggressive the
    optimization phase during use handling will be.  */
 
-static void
+static bool
 ext_dce_process_sets (rtx_insn *insn, rtx obj, bitmap live_tmp)
 {
+  bool skipped_dest = false;
+
   subrtx_iterator::array_type array;
   FOR_EACH_SUBRTX (iter, array, obj, NONCONST)
     {
@@ -158,6 +186,7 @@ ext_dce_process_sets (rtx_insn *insn, rtx obj, bitmap live_tmp)
 	      /* Skip the subrtxs of this destination.  There is
 		 little value in iterating into the subobjects, so
 		 just skip them for a bit of efficiency.  */
+	      skipped_dest = true;
 	      iter.skip_subrtxes ();
 	      continue;
 	    }
@@ -189,13 +218,15 @@ ext_dce_process_sets (rtx_insn *insn, rtx obj, bitmap live_tmp)
 		  /* Skip the subrtxs of the STRICT_LOW_PART.  We can't
 		     process them because it'll set objects as no longer
 		     live when they are in fact still live.  */
+		  skipped_dest = true;
 		  iter.skip_subrtxes ();
 		  continue;
 		}
 
 	      /* Transfer all the LIVENOW bits for X into LIVE_TMP.  */
 	      HOST_WIDE_INT rn = REGNO (SUBREG_REG (x));
-	      for (HOST_WIDE_INT i = 4 * rn; i < 4 * rn + 4; i++)
+	      int limit = group_limit (SUBREG_REG (x)) + 1;
+	      for (HOST_WIDE_INT i = 4 * rn; i < 4 * rn + limit; i++)
 		if (bitmap_bit_p (livenow, i))
 		  bitmap_set_bit (live_tmp, i);
 
@@ -217,11 +248,19 @@ ext_dce_process_sets (rtx_insn *insn, rtx obj, bitmap live_tmp)
 	    = GET_MODE_MASK (GET_MODE_INNER (GET_MODE (x)));
 	  if (SUBREG_P (x))
 	    {
-	      /* If we have a SUBREG that is too wide, just continue the loop
-		 and let the iterator go down into SUBREG_REG.  */
+	      /* If we have a SUBREG destination that is too wide, just
+		 skip the destination rather than continuing this iterator.
+		 While continuing would be better, we'd need to strip the
+		 subreg and restart within the SET processing rather than
+		 the top of the loop which just complicates the flow even
+		 more.  */
 	      if (!is_a <scalar_int_mode> (GET_MODE (SUBREG_REG (x)), &outer_mode)
 		  || GET_MODE_BITSIZE (outer_mode) > 64)
-		continue;
+		{
+		  skipped_dest = true;
+		  iter.skip_subrtxes ();
+		  continue;
+		}
 
 	      /* We can safely strip a paradoxical subreg.  The inner mode will
 		 be narrower than the outer mode.  We'll clear fewer bits in
@@ -246,6 +285,7 @@ ext_dce_process_sets (rtx_insn *insn, rtx obj, bitmap live_tmp)
 		 remain the same.  Thus we can not continue here, we must
 		 either figure out what part of the destination is modified
 		 or skip the sub-rtxs.  */
+	      skipped_dest = true;
 	      iter.skip_subrtxes ();
 	      continue;
 	    }
@@ -286,9 +326,11 @@ ext_dce_process_sets (rtx_insn *insn, rtx obj, bitmap live_tmp)
       else if (GET_CODE (x) == COND_EXEC)
 	{
 	  /* This isn't ideal, but may not be so bad in practice.  */
+	  skipped_dest = true;
 	  iter.skip_subrtxes ();
 	}
     }
+  return skipped_dest;
 }
 
 /* INSN has a sign/zero extended source inside SET that we will
@@ -449,7 +491,12 @@ carry_backpropagate (unsigned HOST_WIDE_INT mask, enum rtx_code code, rtx x)
       return mmask;
 
     case SIGN_EXTEND:
-      if (mask & ~GET_MODE_MASK (GET_MODE_INNER (GET_MODE (XEXP (x, 0)))))
+      /* If there are bits live outside the mode of the object being
+	 extended, then they would be copies of the sign bit of the
+	 object being extended.  So make sure the sign bit of the
+	 object being extended is live in that case.  */
+      mode = GET_MODE_INNER (GET_MODE (XEXP (x, 0)));
+      if (mask & ~GET_MODE_MASK (mode))
 	mask |= 1ULL << (GET_MODE_BITSIZE (mode).to_constant () - 1);
       return mask;
 
@@ -482,7 +529,8 @@ carry_backpropagate (unsigned HOST_WIDE_INT mask, enum rtx_code code, rtx x)
    eliminated in CHANGED_PSEUDOS.  */
 
 static void
-ext_dce_process_uses (rtx_insn *insn, rtx obj, bitmap live_tmp)
+ext_dce_process_uses (rtx_insn *insn, rtx obj,
+		      bitmap live_tmp, bool skipped_dest)
 {
   subrtx_var_iterator::array_type array_var;
   FOR_EACH_SUBRTX_VAR (iter, array_var, obj, NONCONST)
@@ -556,6 +604,15 @@ ext_dce_process_uses (rtx_insn *insn, rtx obj, bitmap live_tmp)
 		  dst_mask |= mask_array[i];
 	      dst_mask >>= bit;
 
+	      /* If we ignored the destination during set processing, then
+		 consider all the bits live.  */
+	      if (skipped_dest)
+		dst_mask = -1;
+
+	      /* Make sure to account for carry_backpropagate before doing
+		 optimization!  */
+	      dst_mask = carry_backpropagate (dst_mask, code, src);
+
 	      /* ??? Could also handle ZERO_EXTRACT / SIGN_EXTRACT
 		 of the source specially to improve optimization.  */
 	      if (code == SIGN_EXTEND || code == ZERO_EXTEND)
@@ -566,7 +623,7 @@ ext_dce_process_uses (rtx_insn *insn, rtx obj, bitmap live_tmp)
 
 		  /* DST_MASK could be zero if we had something in the SET
 		     that we couldn't handle.  */
-		  if (modify && dst_mask && (dst_mask & ~src_mask) == 0)
+		  if (modify && !skipped_dest && (dst_mask & ~src_mask) == 0)
 		    ext_dce_try_optimize_insn (insn, x);
 
 		  dst_mask &= src_mask;
@@ -574,12 +631,6 @@ ext_dce_process_uses (rtx_insn *insn, rtx obj, bitmap live_tmp)
 		  code = GET_CODE (src);
 		}
 
-	      /* Optimization is done at this point.  We just want to make
-		 sure everything that should get marked as live is marked
-		 from here onward.  */
-
-	      dst_mask = carry_backpropagate (dst_mask, code, src);
-
 	      /* We will handle the other operand of a binary operator
 		 at the bottom of the loop by resetting Y.  */
 	      if (BINARY_P (src))
@@ -716,14 +767,15 @@ ext_dce_process_bb (basic_block bb)
       bitmap live_tmp = BITMAP_ALLOC (NULL);
 
       /* First process any sets/clobbers in INSN.  */
-      ext_dce_process_sets (insn, PATTERN (insn), live_tmp);
+      bool skipped_dest = ext_dce_process_sets (insn, PATTERN (insn), live_tmp);
 
       /* CALL_INSNs need processing their fusage data.  */
       if (CALL_P (insn))
-	ext_dce_process_sets (insn, CALL_INSN_FUNCTION_USAGE (insn), live_tmp);
+	skipped_dest |= ext_dce_process_sets (insn, CALL_INSN_FUNCTION_USAGE (insn),
+					      live_tmp);
 
       /* And now uses, optimizing away SIGN/ZERO extensions as we go.  */
-      ext_dce_process_uses (insn, PATTERN (insn), live_tmp);
+      ext_dce_process_uses (insn, PATTERN (insn), live_tmp, skipped_dest);
 
       /* A nonlocal goto implicitly uses the frame pointer.  */
       if (JUMP_P (insn) && find_reg_note (insn, REG_NON_LOCAL_GOTO, NULL_RTX))
@@ -746,7 +798,8 @@ ext_dce_process_bb (basic_block bb)
 	      if (global_regs[i])
 		bitmap_set_range (livenow, i * 4, 4);
 
-	  ext_dce_process_uses (insn, CALL_INSN_FUNCTION_USAGE (insn), live_tmp);
+	  ext_dce_process_uses (insn, CALL_INSN_FUNCTION_USAGE (insn),
+				live_tmp, false);
 	}
 
       BITMAP_FREE (live_tmp);
@@ -816,9 +869,13 @@ ext_dce_init (void)
   unsigned i;
   bitmap_iterator bi;
   EXECUTE_IF_SET_IN_BITMAP (refs, 0, i, bi)
+    make_reg_live (&livein[EXIT_BLOCK], i);
+
+  basic_block bb;
+  FOR_EACH_BB_FN (bb, cfun)
     {
-      for (int j = 0; j < 4; j++)
-	bitmap_set_bit (&livein[EXIT_BLOCK], i * 4 + j);
+      EXECUTE_IF_SET_IN_BITMAP (DF_LR_IN (bb), 0, i, bi)
+	make_reg_live (&livein[bb->index], i);
     }
 
   livenow = BITMAP_ALLOC (NULL);
@@ -875,8 +932,6 @@ ext_dce_rd_transfer_n (int bb_index)
      the generic dataflow code that something changed.  */
   if (!bitmap_equal_p (&livein[bb_index], livenow))
     {
-      gcc_assert (!bitmap_intersect_compl_p (&livein[bb_index], livenow));
-
       bitmap_copy (&livein[bb_index], livenow);
       return true;
     }
