diff --git a/gcc/config/riscv/bitmanip.md b/gcc/config/riscv/bitmanip.md
index 7832f2351ef..9c92921bd58 100644
--- a/gcc/config/riscv/bitmanip.md
+++ b/gcc/config/riscv/bitmanip.md
@@ -141,39 +141,36 @@ (define_insn "*shNadduw"
 ;; The "TARGET_ZBA && clz_hwi (operands[3]) <= 32" check in the
 ;; "*zero_extendsidi2_shifted" pattern over in riscv.md ensures
 ;; that we fall through to here, if appropriate.
-(define_insn_and_split "*slli_slli_uw"
-  [(set (match_operand:DI 0 "register_operand" "=r")
-	(and:DI (ashift:DI (match_operand:DI 1 "register_operand" "r")
-			   (match_operand:QI 2 "dimode_shift_operand" ""))
-		(match_operand:DI 3 "consecutive_bits_operand" "")))
-   (clobber (match_scratch:DI 4 "=&r"))]
+(define_split
+  [(set (match_operand:DI 0 "register_operand")
+	(and:DI (ashift:DI (match_operand:DI 1 "register_operand")
+			   (match_operand:QI 2 "dimode_shift_operand"))
+		(match_operand:DI 3 "consecutive_bits_operand")))
+   (clobber (match_operand:DI 4 "register_operand"))]
   "TARGET_64BIT && TARGET_ZBA
    && popcount_hwi (INTVAL (operands[3])) < 32
    && riscv_shamt_matches_mask_p (INTVAL (operands[2]), INTVAL (operands[3]))
    && IN_RANGE (clz_hwi (INTVAL (operands[3])), 29, 32)"
-  "#"
-  "&& reload_completed"
   [(const_int 0)]
 {
-	unsigned HOST_WIDE_INT mask = INTVAL (operands[3]);
-	/* scale: shamt for the slli.uw */
-	int scale = 32 - clz_hwi (mask);
-	/* bias:  shamt for the prior shift (can be zero) */
-	int bias = ctz_hwi (mask) - scale;
-
-	/* Always emit both the slli and slli.uw, but break the chain
-	   if bias is 0 (and have RTL cleanup remove the dead/dangling
-	   instruction). */
-	emit_insn (gen_rtx_SET (operands[4],
-				gen_rtx_ASHIFT (DImode, operands[1], GEN_INT (bias))));
-	emit_insn (gen_riscv_slli_uw (operands[0],
-				      bias ? operands[4] : operands[1],
-				      GEN_INT (scale),
-				      GEN_INT (HOST_WIDE_INT_C (0xffffffff) << scale)));
-
-	DONE;
-}
-  [(set_attr "type" "bitmanip")])
+  unsigned HOST_WIDE_INT mask = INTVAL (operands[3]);
+  /* scale: shamt for the slli.uw */
+  int scale = 32 - clz_hwi (mask);
+  /* bias:  shamt for the prior shift (can be zero) */
+  int bias = ctz_hwi (mask) - scale;
+
+  /* Always emit both the slli and slli.uw, but break the chain
+     if bias is 0 (and have RTL cleanup remove the dead/dangling
+     instruction). */
+  emit_insn (gen_rtx_SET (operands[4],
+			  gen_rtx_ASHIFT (DImode, operands[1], GEN_INT (bias))));
+  emit_insn (gen_riscv_slli_uw (operands[0],
+				bias ? operands[4] : operands[1],
+				GEN_INT (scale),
+				GEN_INT (HOST_WIDE_INT_C (0xffffffff) << scale)));
+
+  DONE;
+})
 
 ;; During combine, we may encounter an attempt to combine
 ;;   slli rtmp, rs, #imm
@@ -188,40 +185,36 @@ (define_insn_and_split "*slli_slli_uw"
 ;; word. To test for this property, we count the leading zero-bits of
 ;; the mask (which must be in the range [29, 31]).
 
-(define_insn_and_split "*shift_then_shNadd.uw"
-  [(set (match_operand:DI 0 "register_operand" "=r")
-	(plus:DI (and:DI (ashift:DI (match_operand:DI 1 "register_operand" "r")
-				    (match_operand:QI 2 "dimode_shift_operand" ""))
-			 (match_operand:DI 3 "consecutive_bits_operand" ""))
-		 (match_operand:DI 4 "register_operand" "r")))
-   (clobber (match_scratch:DI 5 "=&r"))]
+(define_split
+  [(set (match_operand:DI 0 "register_operand")
+	(plus:DI (and:DI (ashift:DI (match_operand:DI 1 "register_operand")
+				    (match_operand:QI 2 "dimode_shift_operand"))
+			 (match_operand:DI 3 "consecutive_bits_operand"))
+		 (match_operand:DI 4 "register_operand")))
+   (clobber (match_operand:DI 5 "register_operand"))]
   "TARGET_64BIT && TARGET_ZBA
    && riscv_shamt_matches_mask_p (UINTVAL (operands[2]), UINTVAL (operands[3]))
    && IN_RANGE (clz_hwi (UINTVAL (operands[3])), 29, 31)"
-  "#"
-  "&& reload_completed"
   [(set (match_dup 5) (ashift:DI (match_dup 1) (match_dup 6)))
    (set (match_dup 0) (plus:DI (and:DI (ashift:DI (match_dup 5)
 						  (match_dup 7))
 				       (match_dup 8))
 			       (match_dup 4)))]
 {
-	unsigned HOST_WIDE_INT mask = INTVAL (operands[3]);
-	/* scale: shamt for the sh[123]add.uw */
-	unsigned HOST_WIDE_INT scale = 32 - clz_hwi (mask);
-	/* bias:  shamt for the prior shift */
-	unsigned HOST_WIDE_INT bias = ctz_hwi (mask) - scale;
-
-	/* If there's no bias, the '*shNadduw' pattern should have matched. */
-	if (bias == 0)
-	   FAIL;
-
-	operands[6] = GEN_INT (bias);
-	operands[7] = GEN_INT (scale);
-	operands[8] = GEN_INT (HOST_WIDE_INT_C (0xffffffff) << scale);
-}
-  [(set_attr "type" "bitmanip")])
+  unsigned HOST_WIDE_INT mask = INTVAL (operands[3]);
+  /* scale: shamt for the sh[123]add.uw */
+  unsigned HOST_WIDE_INT scale = 32 - clz_hwi (mask);
+  /* bias:  shamt for the prior shift */
+  unsigned HOST_WIDE_INT bias = ctz_hwi (mask) - scale;
+
+  /* If there's no bias, the '*shNadduw' pattern should have matched. */
+  if (bias == 0)
+    FAIL;
 
+  operands[6] = GEN_INT (bias);
+  operands[7] = GEN_INT (scale);
+  operands[8] = GEN_INT (HOST_WIDE_INT_C (0xffffffff) << scale);
+})
 
 (define_insn "*add.uw"
   [(set (match_operand:DI 0 "register_operand" "=r")
